{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOI02-Training Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#labes of train dataset\n",
    "df = pd.read_csv('train.csv')\n",
    "print(df.shape)\n",
    "train_labels = df.iloc[:,1].values\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
    "#Images of train dataset\n",
    "maxTrainNum = 2528\n",
    "#Assign a list for storing image data\n",
    "img_data_list=[]\n",
    "for i in range(0,maxTrainNum):\n",
    "    imgname=\"train_images/train_{0:0>5d}_224.png\".format(i)#first image as train_00000_224.png\n",
    "    img = image.load_img(imgname)\n",
    "    x=image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    img_data_list.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Convert image to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = np.array(img_data_list)\n",
    "print (img_data.shape)  #(2528, 1, 224, 224, 3)\n",
    "img_data=np.rollaxis(img_data,1,0)\n",
    "print (img_data.shape)  #(1, 2528, 224, 224, 3)\n",
    "img_data=img_data[0]\n",
    "print (img_data.shape)  #(2528, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure a customized VGG-16 Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.keras import utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "#input shape\n",
    "###  CODE HERE ###  (≈ 1 lines)\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "#Use the VGG16 model \n",
    "###  CODE HERE ###  (≈ 1 lines)\n",
    "model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "\n",
    "#Summary of the customize VGG16 model\n",
    "###  CODE HERE ###  (≈ 1 lines)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = model.get_layer('fc2').output\n",
    "out = Dense(num_classes, activation='softmax', name='output')(last_layer)\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "custom_vgg_model.summary()\n",
    "\n",
    "for layer in custom_vgg_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Set the model's loss function, optimizer, and metrics\n",
    "###  CODE HERE ###  (≈ 1 lines)\n",
    "custom_vgg_model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Traing the customized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= img_data\n",
    "# one-hot encoding\n",
    "y_train = utils.np_utils.to_categorical(train_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t=time.time()\n",
    "#The parameters for the training model\n",
    "###  CODE HERE ###  (≈ 1 lines)\n",
    "hist = custom_vgg_model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1)\n",
    "print('Training time: %s' % time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save the customized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_model.save(\"myVgg16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
